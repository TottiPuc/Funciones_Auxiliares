{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "colab_snippets.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMpblnY5lfZ1E0YWZYxnu4j"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QW0FKRmTgmEd",
        "colab_type": "text"
      },
      "source": [
        "#Check General Memory and GPU Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kPCTk2UdGJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# memory footprint support libraries/code\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omTD6UU_hPl0",
        "colab_type": "text"
      },
      "source": [
        "#Check GPU memory while training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6wws5zEhO8m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os, time\n",
        "import GPUtil as GPU\n",
        "\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def worker():\n",
        "  if SHOW_GPU_USAGE_TIME == 0:\n",
        "    return;\n",
        "  while True:\n",
        "    process = psutil.Process(os.getpid())\n",
        "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "    time.sleep(SHOW_GPU_USAGE_TIME)\n",
        "\n",
        "import threading\n",
        "t = threading.Thread(target=worker, name='Monitor')\n",
        "t.start()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUvAkiXJhxcx",
        "colab_type": "text"
      },
      "source": [
        "#Send Alert Email at finish"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42ZNcAzUdQJY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import smtplib\n",
        "from email.mime.multipart import MIMEMultipart\n",
        "from email.mime.text import MIMEText\n",
        "try:\n",
        "  server = smtplib.SMTP('smtp.gmail.com', 587)\n",
        "  #server.ehlo()\n",
        "  server.starttls()\n",
        "\n",
        "  with open('password.txt', 'r') as f:\n",
        "    password = f.read()\n",
        "\n",
        "  server.login(\"christiandayan86@gmail.com\", password)\n",
        "  msg = MIMEMultipart()\n",
        "  msg['From'] = \"Googel COLAB\"\n",
        "  msg['To'] = 'dayan3846@gmail.com'\n",
        "  msg['Subject'] = 'COLAB WORK FINISH ALERT!'\n",
        "\n",
        "  with open('message.txt', 'r') as f:\n",
        "  message = f.read()\n",
        "\n",
        "  msg.attach(MIMEText(message, 'plain'))\n",
        "  text = msg.as_string()\n",
        "  server.sendmail(\"christiandayan86@gmail.com\", \"dayan3846@gmail.com\", text)\n",
        "  server.quit()\n",
        "\n",
        "except:\n",
        "  print('Something went wrong...')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ip049mkF7AkL",
        "colab_type": "text"
      },
      "source": [
        "#HyperDash monitoring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l509q1-rpOFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install hyperdash && hyperdash login --email\n",
        "from hyperdash import monitor_cell\n",
        "%%monitor_cell “model/experiment name”"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}